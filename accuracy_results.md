# PICBASIC to Modern Code Conversion Accuracy Results

## Summary Table

| AI Model   | Source File | Functional Accuracy (40) | Structural Adaptation (30) | Code Quality (20) | Additional Features (10) | Total Score (100) |
| ---------- | ----------- | ------------------------ | -------------------------- | ----------------- | ------------------------ | ----------------- |
| ChatGPT    | Order Entry |                          |                            |                   |                          |                   |
| ChatGPT    | Hangman     |                          |                            |                   |                          |                   |
| Claude-3.7 | Order Entry |                          |                            |                   |                          |                   |
| Claude-3.7 | Hangman     | 36                       | 28                         | 19                | 9                        | 92                |
| Gemini     | Order Entry |                          |                            |                   |                          |                   |
| Gemini     | Hangman     |                          |                            |                   |                          |                   |
| DeepSeek   | Order Entry |                          |                            |                   |                          |                   |
| DeepSeek   | Hangman     |                          |                            |                   |                          |                   |

## Comparative Analysis

### Best Overall Performance

_To be completed after evaluations_

### Strengths by Model

#### ChatGPT

_To be completed after evaluations_

#### Claude-3.7

- Excellent at preserving core functionality while modernizing code structure
- Strong documentation practices with clear docstrings
- Effective transformation from procedural to structured programming paradigms
- Strong error handling and input validation

#### Gemini

_To be completed after evaluations_

#### DeepSeek

_To be completed after evaluations_

### Areas for Improvement by Model

#### ChatGPT

_To be completed after evaluations_

#### Claude-3.7

- Could make better use of language-specific optimizations
- Some missed opportunities for more idiomatic code patterns

#### Gemini

_To be completed after evaluations_

#### DeepSeek

_To be completed after evaluations_

## Detailed Evaluation Reports

The following detailed reports are available:

- [ChatGPT - Order Entry](./evaluations/chatgpt_order_entry.md)
- [ChatGPT - Hangman](./evaluations/chatgpt_hangman.md)
- [Claude-3.7 - Order Entry](./evaluations/claude_order_entry.md)
- [Claude-3.7 - Hangman](./evaluations/claude_hangman.md)
- [Gemini - Order Entry](./evaluations/gemini_order_entry.md)
- [Gemini - Hangman](./evaluations/gemini_hangman.md)
- [DeepSeek - Order Entry](./evaluations/deepseek_order_entry.md)
- [DeepSeek - Hangman](./evaluations/deepseek_hangman.md)

## Key Findings

_To be completed after evaluations_

## Recommendations for Tool Improvement

_To be completed after evaluations_
